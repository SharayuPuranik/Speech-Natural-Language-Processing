{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9398532,"sourceType":"datasetVersion","datasetId":5704573},{"sourceId":9398782,"sourceType":"datasetVersion","datasetId":5704800}],"dockerImageVersionId":30762,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport json\nfrom datasets import Dataset\nfrom transformers import BertTokenizerFast, BertForQuestionAnswering, Trainer, TrainingArguments, pipeline\nimport torch\n\nos.environ[\"WANDB_DISABLED\"] = \"true\"\n\ndev_data_path = \"/kaggle/input/stanfordquestionansweringdataset/dev-v1.1.json\"\nwith open(dev_data_path, 'r') as f:\n    dev_data = json.load(f)\n\ntrain_data_path = \"/kaggle/input/questionanswering/train-v1.1.json\" \nwith open(train_data_path, 'r') as f:\n    train_data = json.load(f)\n\ndef prepare_data(data):\n    contexts = []\n    questions = []\n    answers = []\n    \n    for item in data['data']:\n        for para in item['paragraphs']:\n            context = para['context']\n            for qa in para['qas']:\n                question = qa['question']\n                if len(qa['answers']) > 0:\n                    answer = qa['answers'][0]\n                    contexts.append(context)\n                    questions.append(question)\n                    answers.append({\n                        'text': answer['text'],\n                        'answer_start': answer['answer_start']\n                    })\n    return Dataset.from_dict({\n        'context': contexts,\n        'question': questions,\n        'answers': answers\n    })\n\ntrain_dataset = prepare_data(train_data)\ndev_dataset = prepare_data(dev_data)\n\ntokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\nmodel = BertForQuestionAnswering.from_pretrained('bert-base-uncased')\n\ndef preprocess_function(examples):\n    tokenized_inputs = tokenizer(\n        examples[\"question\"],\n        examples[\"context\"],\n        max_length=384,\n        truncation=\"only_second\",\n        padding=\"max_length\",\n        return_offsets_mapping=True,\n        return_tensors=\"pt\"\n    )\n\n    start_positions = []\n    end_positions = []\n\n    for i, offsets in enumerate(tokenized_inputs[\"offset_mapping\"]):\n        answer = examples[\"answers\"][i]\n        start_char = answer[\"answer_start\"]\n        end_char = start_char + len(answer[\"text\"])\n\n        sequence_ids = tokenized_inputs.sequence_ids(i)\n\n        # Find the start and end token positions\n        token_start = 0\n        token_end = 0\n        for idx, (start, end) in enumerate(offsets):\n            if sequence_ids[idx] == 1:\n                if start <= start_char < end:\n                    token_start = idx\n                if start < end_char <= end:\n                    token_end = idx\n\n        start_positions.append(token_start)\n        end_positions.append(token_end)\n\n    tokenized_inputs[\"start_positions\"] = start_positions\n    tokenized_inputs[\"end_positions\"] = end_positions\n    tokenized_inputs.pop(\"offset_mapping\")  \n\n    return tokenized_inputs\n\ntrain_dataset = train_dataset.map(preprocess_function, batched=True)\ndev_dataset = dev_dataset.map(preprocess_function, batched=True)\n\ntraining_args = TrainingArguments(\n    output_dir=\"./results\",\n    eval_strategy=\"epoch\",\n    learning_rate=2e-5,\n    per_device_train_batch_size=16,\n    per_device_eval_batch_size=16,\n    num_train_epochs=1,\n    weight_decay=0.01,\n    report_to=\"none\",\n)\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=dev_dataset,\n    tokenizer=tokenizer,\n)\n\ntrainer.train()\n\nmodel.save_pretrained(\"./question_answering_model\")\ntokenizer.save_pretrained(\"./question_answering_model\")\n\nqa_pipeline = pipeline(\"question-answering\", model=model, tokenizer=tokenizer)\n\nquestion = \"Who won Super Bowl 50?\"\ncontext = \"Denver Broncos defeated the Carolina Panthers 24-10.\"\nresult = qa_pipeline(question=question, context=context)\nprint(f\"Answer: {result['answer']}\")","metadata":{"execution":{"iopub.status.busy":"2024-09-15T06:27:19.496340Z","iopub.execute_input":"2024-09-15T06:27:19.497261Z","iopub.status.idle":"2024-09-15T07:39:06.848455Z","shell.execute_reply.started":"2024-09-15T06:27:19.497199Z","shell.execute_reply":"2024-09-15T07:39:06.847455Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nSome weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/87599 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"39542a8d7563456e9277b6624c10d274"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/10570 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cf8cfb2733784e6e8ab040d8718dd32a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='5475' max='5475' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [5475/5475 1:01:41, Epoch 1/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.078500</td>\n      <td>1.036830</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n","output_type":"stream"},{"name":"stdout","text":"Answer: Denver Broncos\n","output_type":"stream"}]},{"cell_type":"code","source":"question = \"Who did the Denver Broncos defeat in Super Bowl 50?\"\ncontext = \"Denver Broncos defeated the Carolina Panthers 24-10.\"\nresult = qa_pipeline(question=question, context=context)\nprint(f\"Answer: {result['answer']}\")","metadata":{"execution":{"iopub.status.busy":"2024-09-15T07:56:02.211898Z","iopub.execute_input":"2024-09-15T07:56:02.212648Z","iopub.status.idle":"2024-09-15T07:56:02.231700Z","shell.execute_reply.started":"2024-09-15T07:56:02.212606Z","shell.execute_reply":"2024-09-15T07:56:02.230791Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"Answer: Carolina Panthers\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}